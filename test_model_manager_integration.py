#!/usr/bin/env python3
"""
æ¨¡å‹ç®¡ç†å™¨é›†æˆæµ‹è¯•
æµ‹è¯•æ¨¡å‹ç®¡ç†å™¨çš„å®Œæ•´åŠŸèƒ½ï¼ˆä¸å®é™…åŠ è½½å¤§æ¨¡å‹ï¼‰
"""

import sys
import os
from unittest.mock import Mock, patch, MagicMock
sys.path.append('.')

def test_model_manager_initialization():
    """æµ‹è¯•æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–"""
    try:
        # ç”±äºtransformersç‰ˆæœ¬å…¼å®¹é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨mockæ¥æµ‹è¯•
        with patch('src.models.model_manager.AutoTokenizer'), \
             patch('src.models.model_manager.AutoModelForCausalLM'), \
             patch('src.models.model_manager.BitsAndBytesConfig'), \
             patch('src.models.model_manager.GenerationConfig'):
            
            from src.models.model_manager import ModelManager
            from src.core.config import ModelConfig
            
            config = ModelConfig(
                base_model="Qwen/Qwen2.5-7B-Instruct",
                device="cpu",
                max_memory="8GB",
                quantization="4bit",
                embedding_model="BAAI/bge-m3",
                reranker_model="BAAI/bge-reranker-large"
            )
            
            manager = ModelManager(config)
            
            # æµ‹è¯•åŸºç¡€å±æ€§
            assert manager.config == config
            assert not manager._is_loaded
            assert manager.tokenizer is None
            assert manager.model is None
            
            print("âœ… æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_quantization_setup():
    """æµ‹è¯•é‡åŒ–é…ç½®è®¾ç½®"""
    try:
        with patch('src.models.model_manager.BitsAndBytesConfig') as mock_config:
            from src.models.model_manager import ModelManager
            from src.core.config import ModelConfig
            
            # æµ‹è¯•4bité‡åŒ–
            config = ModelConfig(
                base_model="Qwen/Qwen2.5-7B-Instruct",
                device="cpu",
                max_memory="8GB",
                quantization="4bit",
                embedding_model="BAAI/bge-m3",
                reranker_model="BAAI/bge-reranker-large"
            )
            
            manager = ModelManager(config)
            quant_config = manager._setup_quantization()
            
            # éªŒè¯4bité…ç½®è¢«è°ƒç”¨
            mock_config.assert_called_once()
            call_kwargs = mock_config.call_args[1]
            assert call_kwargs['load_in_4bit'] is True
            
            print("âœ… 4bité‡åŒ–é…ç½®æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•8bité‡åŒ–
            mock_config.reset_mock()
            config.quantization = "8bit"
            manager.config = config
            
            quant_config = manager._setup_quantization()
            mock_config.assert_called_once()
            call_kwargs = mock_config.call_args[1]
            assert call_kwargs['load_in_8bit'] is True
            
            print("âœ… 8bité‡åŒ–é…ç½®æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•æ— é‡åŒ–
            config.quantization = "none"
            manager.config = config
            
            quant_config = manager._setup_quantization()
            assert quant_config is None
            
            print("âœ… æ— é‡åŒ–é…ç½®æµ‹è¯•é€šè¿‡")
            
            return True
            
    except Exception as e:
        print(f"âŒ é‡åŒ–é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_device_compatibility():
    """æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§æ£€æŸ¥"""
    try:
        with patch('src.models.model_manager.get_device_manager') as mock_device_manager:
            from src.models.model_manager import ModelManager
            from src.core.config import ModelConfig
            from src.core.exceptions import ConfigurationError
            
            config = ModelConfig(
                base_model="Qwen/Qwen2.5-7B-Instruct",
                device="cpu",
                max_memory="8GB",
                quantization="4bit",
                embedding_model="BAAI/bge-m3",
                reranker_model="BAAI/bge-reranker-large"
            )
            
            # æ¨¡æ‹Ÿè®¾å¤‡ç®¡ç†å™¨
            mock_dm = Mock()
            mock_dm.validate_device_compatibility.return_value = (True, "å…¼å®¹")
            mock_device_manager.return_value = mock_dm
            
            manager = ModelManager(config)
            
            # æµ‹è¯•å…¼å®¹æ€§æ£€æŸ¥
            manager._validate_device_compatibility()
            mock_dm.validate_device_compatibility.assert_called_once_with(config.base_model)
            
            print("âœ… è®¾å¤‡å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡")
            
            # æµ‹è¯•ä¸å…¼å®¹æƒ…å†µ
            mock_dm.validate_device_compatibility.return_value = (False, "ä¸å…¼å®¹")
            
            try:
                manager._validate_device_compatibility()
                assert False, "åº”è¯¥æŠ›å‡ºConfigurationError"
            except ConfigurationError as e:
                assert "è®¾å¤‡ä¸å…¼å®¹" in str(e)
                print("âœ… è®¾å¤‡ä¸å…¼å®¹æ£€æŸ¥é€šè¿‡")
            
            return True
            
    except Exception as e:
        print(f"âŒ è®¾å¤‡å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_info_collection():
    """æµ‹è¯•æ¨¡å‹ä¿¡æ¯æ”¶é›†"""
    try:
        with patch('src.models.model_manager.get_device_manager') as mock_device_manager:
            from src.models.model_manager import ModelManager
            from src.core.config import ModelConfig
            
            config = ModelConfig(
                base_model="Qwen/Qwen2.5-7B-Instruct",
                device="cpu",
                max_memory="8GB",
                quantization="4bit",
                embedding_model="BAAI/bge-m3",
                reranker_model="BAAI/bge-reranker-large"
            )
            
            # æ¨¡æ‹Ÿè®¾å¤‡ç®¡ç†å™¨
            mock_dm = Mock()
            mock_dm.get_memory_info.return_value = {"total": 16.0, "available": 8.0}
            mock_device_manager.return_value = mock_dm
            
            manager = ModelManager(config)
            
            # æ¨¡æ‹Ÿæ¨¡å‹å’Œåˆ†è¯å™¨
            mock_tokenizer = Mock()
            mock_tokenizer.__len__ = Mock(return_value=50000)
            manager.tokenizer = mock_tokenizer
            
            mock_model = Mock()
            mock_model.device = "cpu"
            
            # æ¨¡æ‹Ÿå‚æ•°
            param1 = Mock()
            param1.numel.return_value = 1000
            param1.requires_grad = True
            
            param2 = Mock()
            param2.numel.return_value = 2000
            param2.requires_grad = False
            
            mock_model.parameters.return_value = [param1, param2]
            manager.model = mock_model
            
            manager._load_time = 10.5
            
            # æ”¶é›†ä¿¡æ¯
            info = manager._collect_model_info()
            
            # éªŒè¯ä¿¡æ¯
            assert info["model_name"] == config.base_model
            assert info["device"] == "cpu"
            assert info["quantization"] == "4bit"
            assert info["load_time"] == 10.5
            assert info["vocab_size"] == 50000
            assert info["total_parameters"] == 3000
            assert info["trainable_parameters"] == 1000
            assert "memory_info" in info
            
            print("âœ… æ¨¡å‹ä¿¡æ¯æ”¶é›†æµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¿¡æ¯æ”¶é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_memory_optimization():
    """æµ‹è¯•å†…å­˜ä¼˜åŒ–"""
    try:
        with patch('src.models.model_manager.get_device_manager') as mock_device_manager:
            from src.models.model_manager import ModelManager
            from src.core.config import ModelConfig
            
            config = ModelConfig(
                base_model="Qwen/Qwen2.5-7B-Instruct",
                device="cpu",
                max_memory="8GB",
                quantization="4bit",
                embedding_model="BAAI/bge-m3",
                reranker_model="BAAI/bge-reranker-large"
            )
            
            # æ¨¡æ‹Ÿè®¾å¤‡ç®¡ç†å™¨
            mock_dm = Mock()
            mock_dm.clear_cache = Mock()
            mock_dm.get_memory_info.return_value = {"total": 16.0, "free": 8.0}
            mock_device_manager.return_value = mock_dm
            
            manager = ModelManager(config)
            manager._is_loaded = True
            
            # æµ‹è¯•å†…å­˜ä¼˜åŒ–
            result = manager.optimize_memory()
            
            assert result["status"] == "optimized"
            assert "memory_info" in result
            mock_dm.clear_cache.assert_called_once()
            
            print("âœ… å†…å­˜ä¼˜åŒ–æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•æœªåŠ è½½çŠ¶æ€
            manager._is_loaded = False
            result = manager.optimize_memory()
            assert result["status"] == "model_not_loaded"
            
            print("âœ… æœªåŠ è½½çŠ¶æ€å†…å­˜ä¼˜åŒ–æµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"âŒ å†…å­˜ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_global_functions():
    """æµ‹è¯•å…¨å±€å‡½æ•°"""
    try:
        with patch('src.models.model_manager.ModelManager') as mock_manager_class:
            from src.models.model_manager import get_model_manager, load_qwen_model
            
            # æ¸…ç†å…¨å±€å®ä¾‹
            import src.models.model_manager
            src.models.model_manager._global_model_manager = None
            
            mock_instance = Mock()
            mock_manager_class.return_value = mock_instance
            
            # æµ‹è¯•get_model_manager
            manager1 = get_model_manager()
            assert manager1 == mock_instance
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨åº”è¯¥è¿”å›åŒä¸€å®ä¾‹
            manager2 = get_model_manager()
            assert manager2 == mock_instance
            
            # åªåº”è¯¥åˆ›å»ºä¸€æ¬¡
            mock_manager_class.assert_called_once()
            
            print("âœ… get_model_manageræµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•load_qwen_model
            mock_instance.load_base_model.return_value = ("tokenizer", "model")
            result = load_qwen_model()
            assert result == ("tokenizer", "model")
            mock_instance.load_base_model.assert_called_once()
            
            print("âœ… load_qwen_modelæµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"âŒ å…¨å±€å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æ¨¡å‹ç®¡ç†å™¨é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–", test_model_manager_initialization),
        ("é‡åŒ–é…ç½®è®¾ç½®", test_quantization_setup),
        ("è®¾å¤‡å…¼å®¹æ€§æ£€æŸ¥", test_device_compatibility),
        ("æ¨¡å‹ä¿¡æ¯æ”¶é›†", test_model_info_collection),
        ("å†…å­˜ä¼˜åŒ–", test_memory_optimization),
        ("å…¨å±€å‡½æ•°", test_global_functions),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ è¿è¡Œ {test_name}...")
        try:
            if test_func():
                passed += 1
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†é›†æˆæµ‹è¯•å¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)